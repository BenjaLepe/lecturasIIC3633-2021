# Comentario: Evaluationg Recommendation Systems

Este paper se encarga de mostrarnos una serie de métodos que permiten evaluar a los sistemas recomendadores desde diferentes aristas. En primer lugar, se dan a conocer los tipos de experimentos que se pueden hacer para evaluar a un sistema recomendador, entre los cuales se encuentran los experimentos *Offline*, *User Studies* y *Online Evaluation*. Luego, en lo que resta del texto se muestran distintas propiedades o métricas que se pueden evaluar y permiten ayudar a decidir que algoritmos seleccionar para una tarea en especifico.


Los aspectos más interesantes desde mi punto de vista fueron las características de *Coverage* (Cobertura) y *Novelty* (Novedad), puesto a que ambas van de la mano y son muy importantes dentro de la mayoría de los sistemas recomendadores que existen en la actualidad. Por un lado, *Coverage* busca que la proporción de items recomendados sea lo mayor posible, lo que permite que aumente la diversidad de las recomendaciones y los usuario no elijan siempre los mismos artículos y, por otra parte, *Novelty* busca que los items que se recomienden sean nuevos y, por ende, que nunca hayan sido vistos por el usuario objetivo, algo que si bien no es lo mismo que la métrica antes mencionada, es bastante parecido. Un ejemplo de la utilidad de estas métricas es en el caso de las plataformas musicales como spotify, en donde, en lo personal, es aburrido escuchar siempre la misma música, por lo que sería de gran utilidad que las canciones que me recomendaran fuera música nueva o desconocida.

Me pareció un texto bastante fácil de leer a pesar de su extensión, puesto que se dan muchos ejemplos prácticos y no se ahonda demasiado en las formulas matemáticas. Además, las propiedades estaban muy bien detalladas y se daba mucho enfasis en las posibles consecuencias que podría tener un sistema que no cumpliera con alguna métrica en especifico.